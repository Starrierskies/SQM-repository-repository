name: GaN 2024 Import (monthly upsert)

on:
  workflow_dispatch:
  schedule:
    - cron: "0 5 1 * *" # Runs on the 1st of each month at 05:00 UTC

jobs:
  import-gan-2024:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repo
        uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: "3.11"

      - name: Install dependencies
        run: |
          pip install pandas requests python-dateutil

      - name: Download and import GaN 2024
        env:
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SERVICE_KEY: ${{ secrets.SUPABASE_SERVICE_KEY }}
          TABLE: observations
        run: |
          import pandas as pd
          import requests
          import json
          from dateutil import parser

          URL = "https://globeatnight.org/documents/926/GaN2024.csv"

          print("Downloading GaN 2024…")
          df = pd.read_csv(URL)

          print("Downloaded rows:", len(df))

          # --- Clean and normalize ---
          df.columns = df.columns.str.strip()
          df = df.rename(columns={
              "lat": "latitude",
              "lon": "longitude",
              "magnitude": "sqm_reading"
          })

          # Build timestamp field
          def build_timestamp(date_str, time_str):
              try:
                  return parser.parse(f"{date_str} {time_str}").isoformat()
              except Exception:
                  return None

          if "UTDate" in df.columns and "UTTime" in df.columns:
              df["timestamp_utc"] = df.apply(lambda r: build_timestamp(r["UTDate"], r["UTTime"]), axis=1)
          else:
              df["timestamp_utc"] = None

          # Ensure numeric fields are cleaned
          if "sqm_reading" in df.columns:
              df["sqm_reading"] = pd.to_numeric(df["sqm_reading"], errors="coerce")

          # Add source_tag
          df["source_tag"] = "globe_at_night"

          print("Prepared rows:", len(df))

          # --- Upsert in chunks ---
          url = f"{SUPABASE_URL}/rest/v1/{TABLE}?on_conflict=timestamp_utc,latitude,longitude,source_tag"
          headers = {
              "apikey": SERVICE_KEY,
              "Authorization": f"Bearer {SERVICE_KEY}",
              "Content-Type": "application/json",
              "Prefer": "resolution=merge-duplicates"
          }

          CHUNK = 500
          total = 0
          for i in range(0, len(df), CHUNK):
              # Convert NaN/NaT to None so JSON has null
              chunk_df = df.iloc[i:i+CHUNK].where(pd.notna(df.iloc[i:i+CHUNK]), None)
              chunk = chunk_df.to_dict(orient="records")
              resp = requests.post(url, headers=headers, data=json.dumps(chunk), timeout=300)
              if not resp.ok:
                  raise RuntimeError(f"Upsert error {resp.status_code}: {resp.text[:400]}")
              total += len(chunk)

          print("✅ Upserted rows:", total)
